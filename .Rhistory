summarize(meanpm10 = mean(pm10))
## change parameter settings so that there is a single
## plot in the plot window
par(mfrow=c(1,1))
## Box plot
boxplot(pm_byday$meanpm10,
ylab = "Mean PM10",
main = "Mean PM10 by Day ")
## Customize
#Change color, flip horizontal
boxplot(pm_byday$meanpm10, xlab="Mean PM10",
main="Mean PM 10 by Day",
col="blue", border="darkblue",
pch=16, horizontal=T)
summary(pm_byday$meanpm10)
## Plot separate box plots before and after automation
pm_byday$after <- pm_byday$T>0
#Split into two boxplots
boxplot(pm_byday$meanpm10 ~ pm_byday$after, xlab="Mean PM10",
main="Mean PM 10 by city", col="blue", border="darkblue",
pch=16, horizontal=T, ylab="After Automation")
7/(25+7)
8/28
9/(23+9)
7/28
4/32
6/25
12/32
4/28
# clear environment
rm(list=ls())
# laod libraries
library(tidyverse)
library(rpart)
library(xgboost)
## set seed for reproducability
set.seed(342151)
## set working directory
setwd("/Users/davidarnold/Dropbox/Teaching/ECON280/R/data")
## load data
load("health_cleaned.rdata")
load("health_training_data.rdata")
load("health_test_data.rdata")
## remove first column of both datasets
health.train<- health.train[,-1]
health.test<- health.test[,-1]
## set working directory
setwd("/Users/davidarnold/Dropbox/Teaching/ECON280/R/data")
## load data
load("health_cleaned.rdata")
load("health_training_data.rdata")
load("health_test_data.rdata")
rm(list=ls())
# laod libraries
library(tidyverse)
library(rpart)
library(xgboost)
## set seed for reproducability
set.seed(342151)
## set working directory
setwd("/Users/davidarnold/Dropbox/Teaching/ECON280/R/data")
## load data
load("health_cleaned.rdata")
load("health_training_data.rdata")
load("health_test_data.rdata")
## rpart
## mean heart disease in full pop >=65
mean(health$heart_disease[health$sex==1])
mean(health$heart_disease[health$sex==0 & health$trestbps>=150])
length(health$heart_disease[health$sex==0 & health$trestbps<150])
6/25
8/32
6/(32)
7/28
model.ols <- lm(heart_disease ~ ., data=health.train)
summary(model.ols)
health.test <- health.test %>%
mutate(ols.fitted=predict(model.ols,health.test),
ols.predicted= as.numeric(ols.fitted>=0.5))
View(health.test)
hist(health.test$ols.fitted)
model.logit <- glm(heart_disease ~ ., data=health.train, family="binomial")
health.test <- health.test %>%
mutate(logit.fitted=predict(model.logit,health.test, type="response"),
logit.predicted=as.numeric(logit.fitted>=0.5))
hist(health.test$logit.fitted)
model.rpart <- rpart(as.factor(heart_disease) ~ ., data = health.train)
plotcp(model.rpart)
printcp(model.rpart)
cp1 <- model.rpart$cptable[which.min(model.rpart$cptable[,"xerror"]),"CP"]
cp2 <- 0.18
## clear environment and re-load data
rm(list=ls())
health <- read_csv("health_cleaned.csv")
## prepare data
data.nolabel <- health %>%
select(!c(heart_disease,...1))
data.labels <- health %>%
select(c(heart_disease,...1))
## one-hot encoding of categorical variables
cp <- model.matrix(~as.factor(cp)-1,health)
slope <- model.matrix(~as.factor(slope)-1,health)
ca <- model.matrix(~as.factor(ca)-1,health)
thal <- model.matrix(~as.factor(thal)-1,health)
## remove redundant variables given newly generated categorical variables
data.nolabel <- data.nolabel %>%
select(!c(cp,slope,ca,thal))
## add one-hot encoded
data.nolabel <- cbind(data.nolabel,cp, slope,ca,thal)
## save as data matrix
data.nolabel.matrix <- data.matrix(data.nolabel)
data.labels.matrix <- data.matrix(data.labels)
## test/train split as before
set.seed(1881270)
## 80 percent random sample of rows
trainrows = sample(seq_len(nrow(health)),size = nrow(health)*0.8)
## split to test and training
train.data <- data.nolabel.matrix[trainrows,]
train.labels <- data.labels.matrix[trainrows,]
test.data <- data.nolabel.matrix[-trainrows,]
test.labels <- data.labels.matrix[-trainrows,]
## convert to dmatrices
train.data <- xgb.DMatrix(data=train.data,label=train.labels[,1])
test.data <- xgb.DMatrix(data=test.data,label=test.labels[,1])
bst <- xgboost(data = train.data, max.depth = 6, eta= 0.3, nrounds = 20, objective = "binary:logistic", verbose = 1)
pred <- predict(bst, test.data)
pred.binary <- (pred>=0.5)
table(pred.binary,test.labels[,1])
## Compass Algorithm
##
library(tidyverse)
library(rpart)
## set seed
set.seed(1234)
## setwd
setwd("/Users/davidarnold/Dropbox/Teaching/ECON280/R/code/compas-analysis")
#########################
## Part 1: Cleaning
#########################
## cleaning
raw_data <- read.csv("./compas-scores-two-years.csv")
df <- dplyr::select(raw_data, age, c_charge_degree, race, age_cat, score_text, sex, priors_count,
days_b_screening_arrest, decile_score, is_recid, two_year_recid, c_jail_in, c_jail_out) %>%
filter(days_b_screening_arrest <= 30) %>%
filter(days_b_screening_arrest >= -30) %>%
filter(is_recid != -1) %>%
filter(c_charge_degree != "O") %>%
filter(score_text != 'N/A')
## recast as factors
df <- mutate(df, crime_factor = factor(c_charge_degree)) %>%
mutate(age_factor = as.factor(age_cat)) %>%
within(age_factor <- relevel(age_factor, ref = 1)) %>%
mutate(race_factor = factor(race)) %>%
within(race_factor <- relevel(race_factor, ref = 3)) %>%
mutate(gender_factor = factor(sex, labels= c("Female","Male"))) %>%
within(gender_factor <- relevel(gender_factor, ref = 2)) %>%
mutate(score_factor = factor(score_text != "Low", labels = c("LowScore","HighScore")))
## train split
trainrows = sample(seq_len(nrow(df)),size = nrow(df)*0.7)
## split to test and traing
df.train <- df[trainrows,]
df.test <- df[-trainrows,]
#########################
# Part 2: Predictions
#########################
## ols
ols <- lm(two_year_recid ~ gender_factor + age_factor + race_factor +
as.factor(priors_count) + crime_factor, data=df.train)
## logit
logit <- glm(two_year_recid ~ gender_factor + age_factor + race_factor +
as.factor(priors_count) + crime_factor, family="binomial", data=df.train)
## cart
model.rpart <- rpart(two_year_recid ~ gender_factor + age_factor + race_factor +
priors_count + crime_factor, data = df.train)
cp.opt <- model.rpart$cptable[which.min(model.rpart$cptable[,"xerror"]),"CP"]
model.pruned <- prune(model.rpart,cp=cp.opt)
############################
## Part 3: Converting Continuous Predictions to 10 "Risk Levels"
############################
## binning
breaks <- as.vector(table(df.test$decile_score))
breaks <-c(0,breaks)
for (i in 2:11) {
breaks[i] <- breaks[i-1]+breaks[i]
}
## add predictions on test dataset
df.test <- df.test %>%
mutate(ols.pred=predict(ols,df.test),
logit.pred=predict(logit,df.test,type="response"),
cart.pred=predict(model.pruned,df.test),
)
## now form bins based on how many individuals are in each deciles
## score in the test data (given by breaks)
df.test <- df.test %>%
arrange(ols.pred) %>%
mutate(dec.ols=as.numeric(cut(1:nrow(df.test),breaks=breaks))) %>%
arrange(logit.pred) %>%
mutate(dec.logit=as.numeric(cut(1:nrow(df.test),breaks=breaks))) %>%
arrange(cart.pred) %>%
mutate(dec.cart=as.numeric(cut(1:nrow(df.test),breaks=breaks)))
#############################
## Part 4: Recidivism Rate by Risk Score
#############################
## compute recidivism rates within each decile
acc.compass <- df.test %>% group_by(decile_score) %>%
summarize(recid.rate=mean(is_recid)) %>%
mutate(algorithm="COMPAS")
acc.ols <- df.test %>% group_by(dec.ols) %>%
summarize(recid.rate=mean(is_recid)) %>%
mutate(decile_score=dec.ols,
algorithm="OLS") %>%
select(c(algorithm,decile_score,recid.rate))
acc.logit <- df.test %>% group_by(dec.logit) %>%
summarize(recid.rate=mean(is_recid)) %>%
mutate(decile_score=dec.logit,
algorithm="Logit") %>%
select(c(algorithm,decile_score,recid.rate))
acc.cart <- df.test %>% group_by(dec.cart) %>%
summarize(recid.rate=mean(is_recid)) %>%
mutate(decile_score=dec.cart,
algorithm="CART") %>%
select(c(algorithm,decile_score,recid.rate))
acc <- rbind(acc.compass,acc.ols,acc.logit,acc.cart)
# plot recidivism rates by risk score for each algorithm
acc %>%  ggplot(aes(x=as.factor(decile_score), y=recid.rate, fill=algorithm)) +
geom_bar(position="dodge",stat="identity") +
xlab("Risk Score") +
ylab("Recidivism Rate") +
ggtitle("Comparison of Various Prediction Models")
## Compass Algorithm
##
library(tidyverse)
library(rpart)
## set seed
set.seed(1234)
## setwd
setwd("/Users/davidarnold/Dropbox/Teaching/ECON280/R/code/compas-analysis")
#########################
## Part 1: Cleaning
#########################
## cleaning
raw_data <- read.csv("./compas-scores-two-years.csv")
df <- dplyr::select(raw_data, age, c_charge_degree, race, age_cat, score_text, sex, priors_count,
days_b_screening_arrest, decile_score, is_recid, two_year_recid, c_jail_in, c_jail_out) %>%
filter(days_b_screening_arrest <= 30) %>%
filter(days_b_screening_arrest >= -30) %>%
filter(is_recid != -1) %>%
filter(c_charge_degree != "O") %>%
filter(score_text != 'N/A')
## recast as factors
df <- mutate(df, crime_factor = factor(c_charge_degree)) %>%
mutate(age_factor = as.factor(age_cat)) %>%
within(age_factor <- relevel(age_factor, ref = 1)) %>%
mutate(race_factor = factor(race)) %>%
within(race_factor <- relevel(race_factor, ref = 3)) %>%
mutate(gender_factor = factor(sex, labels= c("Female","Male"))) %>%
within(gender_factor <- relevel(gender_factor, ref = 2)) %>%
mutate(score_factor = factor(score_text != "Low", labels = c("LowScore","HighScore")))
## train split
trainrows = sample(seq_len(nrow(df)),size = nrow(df)*0.7)
## split to test and traing
df.train <- df[trainrows,]
df.test <- df[-trainrows,]
#########################
# Part 2: Predictions
#########################
## ols
ols <- lm(two_year_recid ~ gender_factor + age_factor + race_factor +
as.factor(priors_count) + crime_factor, data=df.train)
## logit
logit <- glm(two_year_recid ~ gender_factor + age_factor + race_factor +
as.factor(priors_count) + crime_factor, family="binomial", data=df.train)
## cart
model.rpart <- rpart(two_year_recid ~ gender_factor + age_factor + race_factor +
priors_count + crime_factor, data = df.train)
cp.opt <- model.rpart$cptable[which.min(model.rpart$cptable[,"xerror"]),"CP"]
model.pruned <- prune(model.rpart,cp=cp.opt)
############################
## Part 3: Converting Continuous Predictions to 10 "Risk Levels"
############################
## binning
breaks <- as.vector(table(df.test$decile_score))
breaks <-c(0,breaks)
for (i in 2:11) {
breaks[i] <- breaks[i-1]+breaks[i]
}
## add predictions on test dataset
df.test <- df.test %>%
mutate(ols.pred=predict(ols,df.test),
logit.pred=predict(logit,df.test,type="response"),
cart.pred=predict(model.pruned,df.test),
)
## now form bins based on how many individuals are in each deciles
## score in the test data (given by breaks)
df.test <- df.test %>%
arrange(ols.pred) %>%
mutate(dec.ols=as.numeric(cut(1:nrow(df.test),breaks=breaks))) %>%
arrange(logit.pred) %>%
mutate(dec.logit=as.numeric(cut(1:nrow(df.test),breaks=breaks))) %>%
arrange(cart.pred) %>%
mutate(dec.cart=as.numeric(cut(1:nrow(df.test),breaks=breaks)))
#############################
## Part 4: Recidivism Rate by Risk Score
#############################
## compute recidivism rates within each decile
acc.compass <- df.test %>% group_by(decile_score) %>%
summarize(recid.rate=mean(is_recid)) %>%
mutate(Algorithm="COMPAS")
acc.ols <- df.test %>% group_by(dec.ols) %>%
summarize(recid.rate=mean(is_recid)) %>%
mutate(decile_score=dec.ols,
Algorithm="OLS") %>%
select(c(algorithm,decile_score,recid.rate))
acc.logit <- df.test %>% group_by(dec.logit) %>%
summarize(recid.rate=mean(is_recid)) %>%
mutate(decile_score=dec.logit,
Algorithm="Logit") %>%
select(c(algorithm,decile_score,recid.rate))
acc.cart <- df.test %>% group_by(dec.cart) %>%
summarize(recid.rate=mean(is_recid)) %>%
mutate(decile_score=dec.cart,
Algorithm="CART") %>%
select(c(algorithm,decile_score,recid.rate))
acc <- rbind(acc.compass,acc.ols,acc.logit,acc.cart)
# plot recidivism rates by risk score for each algorithm
acc %>%  ggplot(aes(x=as.factor(decile_score), y=recid.rate, fill=algorithm)) +
geom_bar(position="dodge",stat="identity") +
xlab("Risk Score") +
ylab("Recidivism Rate") +
ggtitle("Comparison of Various Prediction Models")
## Compass Algorithm
##
library(tidyverse)
library(rpart)
## set seed
set.seed(1234)
## setwd
setwd("/Users/davidarnold/Dropbox/Teaching/ECON280/R/code/compas-analysis")
#########################
## Part 1: Cleaning
#########################
## cleaning
raw_data <- read.csv("./compas-scores-two-years.csv")
df <- dplyr::select(raw_data, age, c_charge_degree, race, age_cat, score_text, sex, priors_count,
days_b_screening_arrest, decile_score, is_recid, two_year_recid, c_jail_in, c_jail_out) %>%
filter(days_b_screening_arrest <= 30) %>%
filter(days_b_screening_arrest >= -30) %>%
filter(is_recid != -1) %>%
filter(c_charge_degree != "O") %>%
filter(score_text != 'N/A')
## recast as factors
df <- mutate(df, crime_factor = factor(c_charge_degree)) %>%
mutate(age_factor = as.factor(age_cat)) %>%
within(age_factor <- relevel(age_factor, ref = 1)) %>%
mutate(race_factor = factor(race)) %>%
within(race_factor <- relevel(race_factor, ref = 3)) %>%
mutate(gender_factor = factor(sex, labels= c("Female","Male"))) %>%
within(gender_factor <- relevel(gender_factor, ref = 2)) %>%
mutate(score_factor = factor(score_text != "Low", labels = c("LowScore","HighScore")))
## train split
trainrows = sample(seq_len(nrow(df)),size = nrow(df)*0.7)
## split to test and traing
df.train <- df[trainrows,]
df.test <- df[-trainrows,]
#########################
# Part 2: Predictions
#########################
## ols
ols <- lm(two_year_recid ~ gender_factor + age_factor + race_factor +
as.factor(priors_count) + crime_factor, data=df.train)
## logit
logit <- glm(two_year_recid ~ gender_factor + age_factor + race_factor +
as.factor(priors_count) + crime_factor, family="binomial", data=df.train)
## cart
model.rpart <- rpart(two_year_recid ~ gender_factor + age_factor + race_factor +
priors_count + crime_factor, data = df.train)
cp.opt <- model.rpart$cptable[which.min(model.rpart$cptable[,"xerror"]),"CP"]
model.pruned <- prune(model.rpart,cp=cp.opt)
############################
## Part 3: Converting Continuous Predictions to 10 "Risk Levels"
############################
## binning
breaks <- as.vector(table(df.test$decile_score))
breaks <-c(0,breaks)
for (i in 2:11) {
breaks[i] <- breaks[i-1]+breaks[i]
}
## add predictions on test dataset
df.test <- df.test %>%
mutate(ols.pred=predict(ols,df.test),
logit.pred=predict(logit,df.test,type="response"),
cart.pred=predict(model.pruned,df.test),
)
## now form bins based on how many individuals are in each deciles
## score in the test data (given by breaks)
df.test <- df.test %>%
arrange(ols.pred) %>%
mutate(dec.ols=as.numeric(cut(1:nrow(df.test),breaks=breaks))) %>%
arrange(logit.pred) %>%
mutate(dec.logit=as.numeric(cut(1:nrow(df.test),breaks=breaks))) %>%
arrange(cart.pred) %>%
mutate(dec.cart=as.numeric(cut(1:nrow(df.test),breaks=breaks)))
#############################
## Part 4: Recidivism Rate by Risk Score
#############################
## compute recidivism rates within each decile
acc.compass <- df.test %>% group_by(decile_score) %>%
summarize(recid.rate=mean(is_recid)) %>%
mutate(Algorithm="COMPAS")
acc.ols <- df.test %>% group_by(dec.ols) %>%
summarize(recid.rate=mean(is_recid)) %>%
mutate(decile_score=dec.ols,
Algorithm="OLS") %>%
select(c(Algorithm,decile_score,recid.rate))
acc.logit <- df.test %>% group_by(dec.logit) %>%
summarize(recid.rate=mean(is_recid)) %>%
mutate(decile_score=dec.logit,
Algorithm="Logit") %>%
select(c(Algorithm,decile_score,recid.rate))
acc.cart <- df.test %>% group_by(dec.cart) %>%
summarize(recid.rate=mean(is_recid)) %>%
mutate(decile_score=dec.cart,
Algorithm="CART") %>%
select(c(Algorithm,decile_score,recid.rate))
acc <- rbind(acc.compass,acc.ols,acc.logit,acc.cart)
# plot recidivism rates by risk score for each algorithm
acc %>%  ggplot(aes(x=as.factor(decile_score), y=recid.rate, fill=algorithm)) +
geom_bar(position="dodge",stat="identity") +
xlab("Risk Score") +
ylab("Recidivism Rate") +
ggtitle("Comparison of Various Prediction Models")
acc %>%  ggplot(aes(x=as.factor(decile_score), y=recid.rate, fill=Algorithm)) +
geom_bar(position="dodge",stat="identity") +
xlab("Risk Score") +
ylab("Recidivism Rate") +
ggtitle("Comparison of Various Prediction Models")
##########################
# Week 8 LAB
##########################
## GGPLOT2 -- All questions should be answered using
## ggplot2 functions
# setup
rm(list=ls())
setwd("/Users/davidarnold/Dropbox/Teaching/EP5/labs/08_lab")
# libraries
library(tidyverse)
##################
# GME PRICE OVER TIME
##################
# 1. In this part of the question we are going to study
# how the price of Gamestop stock has evolved over time
# The gme_clean.csv is a file with the daily stock prices.
# Because a stock price changes over the course of the
# day it has the price at opening, the high and low price of the day
# as well as the closing price of the day.
# load the data
gme <- read_csv("gme_clean.csv")
# create a basic line plot in ggplot2 using the geom_line() function
# closing price should be on the y-axis
# The date should be on the x-axis. Make sure
# to give the plot an appropriate title/labels
gme %>%
ggplot( aes(x=Date, y=Close)) +
geom_line() +
ylab("GME Stock Price ($)") +
ggtitle("GME Stock Price Over Time")
# create a data frame named df_hl which has 3 variables
# Date, High, and Low
df_hl <- gme %>% select(Date,High,Low)
# Next we are going to convert our data into what is referred to as "long" format
# In df_hl, right now, there are 387 observations:
# The unit of observation is the date and there are two variables that hold price information
# When we run the code below it will convert our data to having
# 774 observations (2 observations per date), a variable named "PriceType" which
# indicates whether the corresponding price in a given row is the "High"
# or "Low" price of the day, and then a final variable named "Price" that holds
# the relevant price.
df_long_hl <- pivot_longer(df_hl,!Date, names_to="PriceType", values_to="Price")
# Look at df_long_hl and df_hl to make sure you understand the difference
# between the two. They hold the same information, but are structured differently
# In this class you won't need to use pivot_longer yourself, but you should
# understand after looking at the two dataframes how they differ.
# create a line plot with two lines
# The first will be the high price and
# the second will be the low price.
# the code below is partially filled out to help you
# In general, when you want to do the same figure by different groups, you
# can specify "color=group". In our case, we specify "color=PriceType"
# because we want a separate line for each PriceType
df_long_hl %>%
ggplot( aes(x=Date, y=Price, color=PriceType) ) +
geom_line() +
ylab("GME Stock Price ($)") +
ggtitle("GME Stock Price Over Time")
##################
# Olympic Athlete Ages
##################
# clear environment
rm(list=ls())
# load Olympic data
olympics <- read_csv("athlete_events.csv")
# Create a table that displays the frequency of each Olympic event in the dataset
# We used this function at the end of Week 6 Part 1, as well as Video 6.10
table(olympics$Event)
# Pick 2 events you are interested in and create a data
# frame that is filtered only to those two events
# you will have to use a logical operator to accomplish this
sub <- olympics %>% filter(Event=="Curling Men's Curling" |
Event=="Gymnastics Women's Team All-Around")
summary(sub$Age[sub$Event=="Curling Men's Curling"])
27-15
summary(sub$Age[sub$Event=="Gymnastics Women's Team All-Around"])
